{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../build')\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import libry as ry\n",
    "import time\n",
    "print(cv.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's edit the real world before we create the simulation\n",
    "RealWorld = ry.Config()\n",
    "RealWorld.addFile(\"../../scenarios/challenge.g\")\n",
    "V = ry.ConfigurationViewer()\n",
    "V.setConfiguration(RealWorld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change some colors\n",
    "RealWorld.getFrame(\"obj0\").setColor([0,1,0])\n",
    "RealWorld.getFrame(\"obj1\").setColor([0,1,0])\n",
    "RealWorld.getFrame(\"obj2\").setColor([1,1,0])\n",
    "RealWorld.getFrame(\"obj3\").setColor([1,0,1])\n",
    "RealWorld.getFrame(\"obj4\").setColor([0,1,1])\n",
    "\n",
    "#you can also change the shape & size\n",
    "RealWorld.getFrame(\"obj0\").setColor([1.,0,0])\n",
    "RealWorld.getFrame(\"obj0\").setShape(ry.ST.sphere, [.03])\n",
    "#RealWorld.getFrame(\"obj0\").setShape(ry.ST.ssBox, [.05, .05, .2, .01])\n",
    "RealWorld.getFrame(\"obj0\").setPosition([0., .2, 2.])\n",
    "\n",
    "#remove some objects\n",
    "for o in range(5,30):\n",
    "    name = \"obj%i\" % o\n",
    "    #print(\"deleting\", name)\n",
    "    RealWorld.delFrame(name)\n",
    "\n",
    "V.recopyMeshes(RealWorld)\n",
    "V.setConfiguration(RealWorld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<libry.CameraViewSensor at 0x7f87b01b6848>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the simulation\n",
    "S = RealWorld.simulation(ry.SimulatorEngine.physx, True)\n",
    "S.addSensor(\"camera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're adding an \"imp\" to the simulation, which is a little process that can inject perturbations\n",
    "# S.addImp(ry.ImpType.objectImpulses, ['obj0'], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your model world\n",
    "C = ry.Config()\n",
    "C.addFile('../../scenarios/pandasTable.g')\n",
    "#V = ry.ConfigurationViewer()\n",
    "V.setConfiguration(C)\n",
    "cameraFrame = C.frame(\"camera\")\n",
    "\n",
    "#the focal length\n",
    "f = 0.895\n",
    "f = f * 360.\n",
    "fxfypxpy = [f, f, 320., 180.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preception(rgb):\n",
    "    # Segment Red sphere\n",
    "    # Load an color image as HSV\n",
    "    # converting from BGR to HSV color space\n",
    "    hsv_img = cv.cvtColor(rgb, cv.COLOR_BGR2HSV)\n",
    "        \n",
    "    # Filter the color of the image to find all pixels that are redish.\n",
    "\n",
    "    # Threshold the HSV image, keep only the red pixels\n",
    "    red_lowerth = np.array([0,100,90])\n",
    "    red_upperth = np.array([10,255,255])\n",
    "    red_mask1 = cv.inRange(hsv_img, red_lowerth, red_upperth)\n",
    "\n",
    "    # Range for upper range\n",
    "    red_lowerth = np.array([160,100,90])\n",
    "    red_upperth = np.array([180,255,255])\n",
    "    red_mask2 = cv.inRange(hsv_img,red_lowerth,red_upperth)\n",
    "    \n",
    "    # Generating the final mask to detect red color and find all pixels that are \n",
    "    red_mask = cv.addWeighted(red_mask1, 1, red_mask2, 1, 0)\n",
    "    #red_mask = cv.GaussianBlur(red_mask, (9, 9), 0)\n",
    "    cv.imshow(\"Masked_Image\",red_mask)\n",
    "    \n",
    "    # Get only the circle \n",
    "        \n",
    "    # Set my output imgage pixel value to zero everywhere except my mask\n",
    "    red_obj_img = rgb.copy()\n",
    "    red_obj_img[np.where(red_mask==0)] = 0\n",
    "    #cv.imshow(\"Masked_Image\",red_obj_img)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Detect circles using Hough Transform - Not Working\n",
    "    # void cv::HoughCircles(InputArray image, int method, double dp, double minDist, \n",
    "    #                       double param1 = 100, double param2 = 100, int minRadius = 0, int maxRadius = 0)\n",
    "    \n",
    "    height, width = red_mask.shape\n",
    "    # Debug\n",
    "    # print(\"Height - \", height, \"Width - \", width)\n",
    "    # circles = cv.HoughCircles(red_mask, cv.HOUGH_GRADIENT, 1, (width*height)/8, 80, 50, 1)\n",
    "        \n",
    "    circles = cv.HoughCircles(red_mask,cv.HOUGH_GRADIENT,1,(width*height)/8,param1=50,param2=50,minRadius=5,maxRadius=0)\n",
    "    print(circles)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    # Detect circles using contour\n",
    "    # Find contours for the objects detected in mask\n",
    "    # contours, hierarchy=cv.findContours(image, mode, method[, contours[, hierarchy[, offset]]])\n",
    "    contours, _ = cv.findContours(red_mask, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
    "\n",
    "    red_mask_ret = red_mask.copy()\n",
    "    for contour in contours:\n",
    "        # If contour area too small ignore it\n",
    "        # if abs(cv.contourArea(contour)) < 10000:\n",
    "            # continue\n",
    "        \n",
    "        # Approximate to a polygon of less vertices\n",
    "        peri = cv.arcLength(contour, True)\n",
    "        # void cv::approxPolyDP (InputArray curve, OutputArray approxCurve, double epsilon, bool closed)\n",
    "        approx = cv.approxPolyDP(contour, 0.04 * peri, True)\n",
    "        \n",
    "        print(\"approx\", len(approx))\n",
    "        \n",
    "        # Choose first circle, can be adapted later and  \n",
    "        if len(approx) < 7 and not cv.isContourConvex(approx):\n",
    "            for i in range(red_mask_ret.shape[0]):\n",
    "                for j in range(red_mask_ret.shape[1]):\n",
    "                    if ( cv.pointPolygonTest(contour, (i,j), False) < 0):\n",
    "                        red_mask_ret[i,j] = 0          \n",
    "            break\n",
    "    \n",
    "    cv.imshow(\"Masked_Image\",red_mask_ret)\n",
    "    \"\"\"\n",
    "    \n",
    "    return red_mask, red_obj_img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(533, 3)\n",
      "(763, 3)\n",
      "(980, 3)\n",
      "(1185, 3)\n",
      "(1394, 3)\n",
      "(1601, 3)\n",
      "(1808, 3)\n",
      "(2014, 3)\n",
      "(2223, 3)\n",
      "(2432, 3)\n",
      "(2637, 3)\n",
      "(2842, 3)\n",
      "(3047, 3)\n",
      "(3256, 3)\n",
      "(3464, 3)\n",
      "(3670, 3)\n",
      "(3881, 3)\n",
      "(4088, 3)\n",
      "(4293, 3)\n",
      "(4506, 3)\n",
      "(4714, 3)\n",
      "(4923, 3)\n",
      "(5136, 3)\n",
      "(5345, 3)\n",
      "(5557, 3)\n",
      "(5771, 3)\n",
      "(5982, 3)\n",
      "(6196, 3)\n",
      "(6410, 3)\n",
      "(6622, 3)\n",
      "(6836, 3)\n",
      "(7052, 3)\n",
      "(7266, 3)\n",
      "(7483, 3)\n",
      "(7699, 3)\n",
      "(7913, 3)\n"
     ]
    }
   ],
   "source": [
    "points = []\n",
    "cll_point = []\n",
    "\n",
    "tau = .01\n",
    "\n",
    "# Initial seen depth and RGB for default point cloud\n",
    "[rgb_init, depth_init] = S.getImageAndDepth()\n",
    "init_points = S.depthData2pointCloud(depth_init, fxfypxpy)\n",
    "\n",
    "for t in range(400):\n",
    "    time.sleep(0.01)\n",
    "            \n",
    "    #grab sensor readings from the simulation\n",
    "    q = S.get_q()\n",
    "    if t%10 == 0:\n",
    "        \n",
    "        [rgb, depth] = S.getImageAndDepth()  #we don't need images with 100Hz, rendering is slow\n",
    "        \n",
    "        # Changes for OpenCV dispaly\n",
    "        rgb = cv.cvtColor(rgb, cv.COLOR_BGR2RGB)\n",
    "        \n",
    "        #points = S.depthData2pointCloud(depth, fxfypxpy)\n",
    "        #cameraFrame.setPointCloud(points, rgb)\n",
    "        #V.recopyMeshes(C)\n",
    "        #V.setConfiguration(C)\n",
    "        \n",
    "        #np.argwhere(img == 255)\n",
    "            \n",
    "        if len(rgb)>0: cv.imshow('OPENCV - rgb', rgb)\n",
    "        if len(depth)>0: cv.imshow('OPENCV - depth', 0.5* depth)\n",
    "\n",
    "        # Start the pipeline\n",
    "        \n",
    "        # Stage 1: Perception Pipeline\n",
    "        red_mask, red_obj = preception(rgb)\n",
    "        red_obj = cv.cvtColor(red_obj, cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        # collect all image points that belong to the object into a n-times-3 matrix with rows\n",
    "        img_point_rgb = rgb_init.copy()\n",
    "        img_point_depth = depth_init.copy()\n",
    "        \n",
    "        # Debug\n",
    "        #print(np.array(img_point_rgb).shape)\n",
    "        #print(np.array(img_point_depth).shape)\n",
    "        \n",
    "        for x in range(red_mask.shape[0]):\n",
    "            for y in range(red_mask.shape[1]):\n",
    "                if(red_mask[x,y] != 0):\n",
    "                    img_point_rgb[x,y] = red_obj[x,y]\n",
    "                    img_point_depth[x,y] = depth[x,y]\n",
    "                    #cll_rgb.append(img_points[x,y])\n",
    "                    #cll_depth.append(img_points[x,y])\n",
    "        \n",
    "        # Transform that point cloud into meter coordinates\n",
    "        img_points = S.depthData2pointCloud(img_point_depth, fxfypxpy)\n",
    "        \n",
    "        for x in range(red_mask.shape[0]):\n",
    "            for y in range(red_mask.shape[1]):\n",
    "                if(red_mask[x,y] != 0):\n",
    "                    cll_point.append(img_points[x,y])\n",
    "                         \n",
    "        print(np.array(cll_point).shape)\n",
    "                    \n",
    "        # Display this point could by attaching it as shape to the cameraFrame\n",
    "        cameraFrame.setPointCloud(img_points, img_point_rgb)\n",
    "        V.recopyMeshes(C)\n",
    "        V.setConfiguration(C)\n",
    "        \n",
    "        # Compute the mean of the point cloud\n",
    "        point_mean = np.mean(cll_point, axis=0)\n",
    "        \n",
    "        # Debug\n",
    "        #print(\"Mean is \", point_mean)\n",
    "        \n",
    "        \"\"\"\n",
    "        # Path\n",
    "        IK = C.komo_IK(False)\n",
    "        \n",
    "        # addObjective(times, featureSymbol, frameNames, objectiveType, scale, target, order)\n",
    "        # To prevent collisions\n",
    "        IK.addObjective([], ry.FS.accumulatedCollisions, [], ry.OT.ineq, [1e1])\n",
    "\n",
    "        # Position difference between gripper centre is 0\n",
    "        IK.addObjective([1], ry.FS.positionDiff, ['R_gripperCenter', point_mean], ry.OT.sos, [1e1])\n",
    "\n",
    "        # Calling the optimizer (True means random initialization/restart)\n",
    "        IK.optimize(True)\n",
    "        IK.getReport()\n",
    "\n",
    "        qT = IK.getConfiguration(0)\n",
    "        q0 = C.getFrameState()\n",
    "\n",
    "        MP = (1 - math.cos(math.pi * t / 250)) / 2\n",
    "        q = q0 + MP * (qT - q0)\n",
    "        C.setFrameState(q)\n",
    "        V.setConfiguration(C)\n",
    "        \n",
    "        # Assuming at 250 u reach the object. Should be done only when reached the goal position. \n",
    "        if t==250:\n",
    "        S.closeGripper(\"gripper\")\n",
    "        \"\"\"\n",
    "        \n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    S.step([], tau, ry.ControlMode.none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set contacts for coliision handling\n",
    "\n",
    "#Contact for table\n",
    "Table = C.frame(\"table\")\n",
    "Table.setContact(1)\n",
    "\n",
    "# Contact for Right gripper and fingers\n",
    "R_gripper = C.frame(\"R_gripper\")\n",
    "R_gripper.setContact(1)\n",
    "R_gripperCenter = C.frame(\"R_gripperCenter\")\n",
    "R_gripperCenter.setContact(1)\n",
    "R_finger1 = C.frame(\"R_finger1\")\n",
    "R_finger1.setContact(1)\n",
    "R_finger2 = C.frame(\"R_finger2\")\n",
    "R_finger2.setContact(1)\n",
    "\n",
    "\n",
    "# Contact for Left gripper\n",
    "L_gripper = C.frame(\"L_gripper\")\n",
    "L_gripper.setContact(1)\n",
    "L_finger1 = C.frame(\"L_finger1\")\n",
    "L_finger1.setContact(1)\n",
    "L_finger2 = C.frame(\"L_finger2\")\n",
    "L_finger2.setContact(1)\n",
    "\n",
    "\n",
    "# Contact for object\n",
    "obj0.setContact(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = komo.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V.playVideo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.setFrameState(komo.getConfiguration(19))\n",
    "C.getJointState()\n",
    "V.setConfiguration(C)\n",
    "coll = C.feature(ry.FS.accumulatedCollisions, [])\n",
    "C.computeCollisions() \n",
    "coll.eval(C)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
